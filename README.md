# knowledge-database

è¯­ä¹‰ç§‘æŠ€æ™ºèƒ½ä½“å¹³å°çŸ¥è¯†åº“

## åŠŸèƒ½ç‰¹æ€§

- ğŸ” è¯­ä¹‰æœç´¢å’Œå‘é‡æ£€ç´¢
- ğŸ“š çŸ¥è¯†åº“ç®¡ç†ï¼ˆå¢åˆ æ”¹æŸ¥ï¼‰
- ğŸ”— çŸ¥è¯†ç‚¹ç»‘å®šå’Œè§£ç»‘
- ğŸ“„ **æ–‡æ¡£å¤„ç†** - è‡ªåŠ¨è§£æå’Œåˆ†å—æ–‡æ¡£
- âœ‚ï¸ **æ–‡æœ¬åˆ†å—** - ç›´æ¥æ–‡æœ¬å¤„ç†å’Œæ™ºèƒ½åˆ†å—
- ğŸ¤– **Difyå¹³å°é›†æˆ** - æä¾›Difyå…¼å®¹çš„å¤–éƒ¨çŸ¥è¯†åº“API
- ğŸ“Š åŸºäºElasticsearchçš„é«˜æ€§èƒ½æœç´¢
- ğŸš€ FastAPIå¼‚æ­¥æ¡†æ¶

## ç¯å¢ƒè¦æ±‚
- Linux
- uv
- Docker & Docker Composeï¼ˆæ¨èï¼‰
- Elasticsearchï¼ˆDockerè‡ªåŠ¨æä¾›ï¼‰
- Python 3.12+ï¼ˆæœ¬åœ°å¼€å‘ï¼‰
- RAGFlow APIæœåŠ¡ï¼ˆç”¨äºæ–‡æ¡£è§£æå’Œåˆ†å—ï¼‰

## å®‰è£…å’Œè¿è¡Œ

### å®‰è£…ä¾èµ–
```shell
uv sync
```

### Dockeræ–¹å¼ï¼ˆæ¨èï¼‰

#### ä½¿ç”¨Docker Composeï¼ˆä¸€é”®å¯åŠ¨å®Œæ•´ç¯å¢ƒï¼‰
```shell
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘.envæ–‡ä»¶ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é»˜è®¤é…ç½®å¯ç›´æ¥è·³è¿‡ï¼‰
nano .env

# æ„å»ºå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆAPI + Elasticsearchï¼‰
docker-compose up --build

# åå°è¿è¡Œ
docker-compose up -d --build

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

#### å•ç‹¬ä½¿ç”¨Docker
```shell
# æ„å»ºé•œåƒ
docker build -t knowledge-db .

# è¿è¡ŒAPIæœåŠ¡
docker run -p 5001:5001 knowledge-db
```

### æœ¬åœ°å¼€å‘æ–¹å¼

#### å¯åŠ¨APIæœåŠ¡ï¼ˆåŒ…å«Difyé›†æˆï¼‰
```shell
python main.py serve --host 0.0.0.0 --port 5001
```

ä¸€ä¸ªæœåŠ¡æä¾›æ‰€æœ‰åŠŸèƒ½ï¼š
- çŸ¥è¯†ç®¡ç†API (CRUDæ“ä½œ)
- æ–‡æ¡£å¤„ç†å’Œåˆ†å—ï¼ˆä½¿ç”¨RAGFlowï¼‰
- Difyå¤–éƒ¨çŸ¥è¯†åº“API (`/retrieval`ç«¯ç‚¹)
- å¥åº·æ£€æŸ¥å’ŒAPIæ–‡æ¡£

## å¯ç”¨å‘½ä»¤

```bash
# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤
python main.py --help

# å¯åŠ¨APIæœåŠ¡ï¼ˆåŒ…å«çŸ¥è¯†ç®¡ç†+Difyé›†æˆï¼Œé»˜è®¤ç«¯å£5001ï¼‰
python main.py serve

# å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
python main.py serve --reload

# è‡ªå®šä¹‰ç«¯å£
python main.py serve --port 8000
```

## RAGFlowé…ç½®

åœ¨ä½¿ç”¨æ–‡æ¡£å¤„ç†åŠŸèƒ½ä¹‹å‰ï¼Œéœ€è¦é…ç½®RAGFlowæœåŠ¡ï¼š

### ç¯å¢ƒå˜é‡
```bash
# RAGFlow APIé…ç½®
export RAGFLOW_API_KEY="your-ragflow-api-key"
export RAGFLOW_BASE_URL="http://your-ragflow-server:9380"
```

### Dockerç¯å¢ƒ
åœ¨docker-compose.ymlæˆ–.envæ–‡ä»¶ä¸­é…ç½®ï¼š
```env
RAGFLOW_API_KEY=your-ragflow-api-key
RAGFLOW_BASE_URL=http://your-ragflow-server:9380
```

### æœ¬åœ°å¼€å‘
å¦‚æœRAGFlowè¿è¡Œåœ¨æœ¬åœ°ï¼Œé»˜è®¤é…ç½®ä¸ºï¼š
```env
RAGFLOW_API_KEY=ragflow-test-key-12345
RAGFLOW_BASE_URL=http://localhost:9380
```

## APIæ–‡æ¡£

### ç»Ÿä¸€APIæœåŠ¡
- **ç«¯å£**: 5001 (é»˜è®¤)
- **çŸ¥è¯†ç®¡ç†APIæ–‡æ¡£**: [çŸ¥è¯†ç®¡ç†æ¥å£æ–‡æ¡£](./docs/çŸ¥è¯†ç®¡ç†æ¥å£.md)
- **çŸ¥è¯†åˆ†ç‰‡æ¥å£æ–‡æ¡£**: [çŸ¥è¯†åˆ†ç‰‡æ¥å£æ–‡æ¡£](./docs/çŸ¥è¯†åˆ†ç‰‡æ¥å£.md)
- **Difyé›†æˆæ–‡æ¡£**: [Difyå¤–éƒ¨çŸ¥è¯†åº“APIæ–‡æ¡£](./docs/Difyå¤–éƒ¨çŸ¥è¯†åº“API.md)
- **å®Œæ•´APIä¿¡æ¯**: è®¿é—® `http://localhost:5001/` è·å–æ‰€æœ‰å¯ç”¨ç«¯ç‚¹å’Œè¯¦ç»†è¯´æ˜

### å¯ç”¨ç«¯ç‚¹æ¦‚è§ˆ
- **çŸ¥è¯†ç®¡ç†**: CRUDæ“ä½œã€è¯­ä¹‰æœç´¢ã€å‘é‡æ£€ç´¢
- **æ–‡æ¡£å¤„ç†**: ä¸Šä¼ ã€è§£æã€åˆ†å—å¤„ç†
- **æ–‡æœ¬åˆ†å—**: ç›´æ¥æ–‡æœ¬æ™ºèƒ½åˆ†å—
- **Difyé›†æˆ**: å¤–éƒ¨çŸ¥è¯†åº“API (`/retrieval`)
- **ç³»ç»Ÿ**: å¥åº·æ£€æŸ¥ã€APIæ–‡æ¡£

## å¿«é€Ÿé›†æˆDify

### Dockeræ–¹å¼ï¼ˆæ¨èï¼‰
1. é…ç½®RAGFlowæœåŠ¡å’Œå¯åŠ¨å®Œæ•´æœåŠ¡ï¼š
```bash
# å¤åˆ¶å¹¶ç¼–è¾‘ç¯å¢ƒå˜é‡
cp .env.example .env
# é…ç½®RAGFLOW_API_KEYå’ŒRAGFLOW_BASE_URL

# å¯åŠ¨æœåŠ¡
docker-compose up -d --build
```

2. åœ¨Difyå¹³å°ä¸­é…ç½®å¤–éƒ¨çŸ¥è¯†åº“ï¼š
   - APIç«¯ç‚¹ï¼š`http://localhost:5001/retrieval`
   - APIå¯†é’¥ï¼šä»»æ„é•¿åº¦è¶…è¿‡10ä½çš„å­—ç¬¦ä¸²
   - æµ‹è¯•è¿æ¥ç¡®è®¤é…ç½®æ­£ç¡®

### æœ¬åœ°æ–¹å¼
1. å¯åŠ¨APIæœåŠ¡ï¼š
```bash
python main.py serve --host 0.0.0.0 --port 5001
```

2. åœ¨Difyå¹³å°ä¸­é…ç½®å¤–éƒ¨çŸ¥è¯†åº“ï¼š
   - APIç«¯ç‚¹ï¼š`http://your-server:5001/retrieval`
   - APIå¯†é’¥ï¼šä»»æ„é•¿åº¦è¶…è¿‡10ä½çš„å­—ç¬¦ä¸²
   - æµ‹è¯•è¿æ¥ç¡®è®¤é…ç½®æ­£ç¡®

3. å¼€å§‹åœ¨Difyä¸­ä½¿ç”¨ä½ çš„çŸ¥è¯†åº“ï¼

## é¡¹ç›®ç»“æ„

```
knowledge-database/
â”œâ”€â”€ main.py                           # CLIå…¥å£
â”œâ”€â”€ Dockerfile                        # Dockeré•œåƒæ„å»ºæ–‡ä»¶
â”œâ”€â”€ docker-compose.yml               # Docker Composeé…ç½®
â”œâ”€â”€ pyproject.toml                   # Pythoné¡¹ç›®é…ç½®
â”œâ”€â”€ dify_kg_ext/
â”‚   â”œâ”€â”€ api.py                       # ç»Ÿä¸€APIï¼ˆçŸ¥è¯†ç®¡ç†+Difyé›†æˆï¼‰
â”‚   â”œâ”€â”€ dataclasses/                 # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ es.py                        # Elasticsearchæ“ä½œ
â”‚   â”œâ”€â”€ worker.py                    # Celery worker
â”‚   â””â”€â”€ adapters/                    # é€‚é…å™¨å±‚
â”œâ”€â”€ tests/                           # æµ‹è¯•æ–‡ä»¶
â””â”€â”€ docs/
    â”œâ”€â”€ çŸ¥è¯†ç®¡ç†æ¥å£.md               # çŸ¥è¯†ç®¡ç†APIæ–‡æ¡£
    â”œâ”€â”€ çŸ¥è¯†åˆ†ç‰‡æ¥å£.md               # çŸ¥è¯†åˆ†ç‰‡APIæ–‡æ¡£
    â””â”€â”€ Difyå¤–éƒ¨çŸ¥è¯†åº“API.md          # Dify APIæ–‡æ¡£
```

## Dockerç¯å¢ƒå˜é‡é…ç½®

### ä½¿ç”¨.envæ–‡ä»¶
æ‰€æœ‰Dockerç¯å¢ƒå˜é‡éƒ½å¯ä»¥é€šè¿‡`.env`æ–‡ä»¶é…ç½®ï¼š

```bash
# å¤åˆ¶ç¤ºä¾‹æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘é…ç½®
nano .env
```

### ç¯å¢ƒå˜é‡è¯´æ˜
| å˜é‡å | é»˜è®¤å€¼ | æè¿° |
|--------|--------|------|
| `REDIS_HOST` | `redis` | Rediså®¹å™¨åç§° |
| `REDIS_PORT` | `6379` | RedisæœåŠ¡ç«¯å£ |
| `ELASTICSEARCH_HOST` | `elasticsearch` | Elasticsearchå®¹å™¨åç§° |
| `ELASTICSEARCH_PORT` | `9200` | ElasticsearchæœåŠ¡ç«¯å£ |
| `API_HOST` | `0.0.0.0` | APIæœåŠ¡ç»‘å®šåœ°å€ |
| `API_PORT` | `5001` | APIæœåŠ¡ç«¯å£ |
| `WORKER_CONCURRENCY` | `2` | Workerè¿›ç¨‹æ•° |
| `WORKER_LOG_LEVEL` | `info` | Workeræ—¥å¿—çº§åˆ« |
| `DATA_PATH` | `./data` | æ•°æ®ç›®å½•æŒ‚è½½è·¯å¾„ |
| `ES_JAVA_OPTS` | `-Xms512m -Xmx512m` | Elasticsearch JVMå†…å­˜è®¾ç½® |
| `SMALL_MODEL_BACKEND` | `siliconflow` | æ¨¡å‹åç«¯ç±»å‹ |
| `SILICONFLOW_TOKEN` | - | SiliconFlow APIä»¤ç‰Œ |
| `DOCLING_ARTIFACTS_PATH` | `~/.cache/docling/models` | Doclingæ¨¡å‹ç¼“å­˜è·¯å¾„ |

### è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹
```bash
# ä¿®æ”¹ç«¯å£é¿å…å†²çª
API_PORT=8080
ELASTICSEARCH_PORT=9201
REDIS_PORT=6380

# å¢åŠ workerå¹¶å‘æ•°
WORKER_CONCURRENCY=4

# ä¿®æ”¹æ•°æ®ç›®å½•
DATA_PATH=/opt/knowledge-db/data
```

### æ•…éšœæ’é™¤

#### Dockerå¸¸è§é—®é¢˜
1. **ç«¯å£å†²çª**ï¼šä¿®æ”¹`.env`æ–‡ä»¶ä¸­çš„ç«¯å£é…ç½®
2. **å†…å­˜ä¸è¶³**ï¼šè°ƒæ•´`ES_JAVA_OPTS`å‚æ•°ï¼Œå¦‚`-Xms1g -Xmx1g`
3. **æƒé™é—®é¢˜**ï¼šç¡®ä¿å½“å‰ç”¨æˆ·æœ‰Dockeræƒé™

#### æ—¥å¿—æŸ¥çœ‹
```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker-compose logs -f api
docker-compose logs -f elasticsearch
```

#### æ–‡æ¡£å¤„ç†æ•…éšœ
- **RAGFlowè¿æ¥å¤±è´¥**ï¼šæ£€æŸ¥RAGFLOW_BASE_URLå’ŒRAGFLOW_API_KEYé…ç½®
- **æ–‡æ¡£è§£æå¤±è´¥**ï¼šç¡®ä¿RAGFlowæœåŠ¡æ­£å¸¸è¿è¡Œ
- **å¤„ç†è¶…æ—¶**ï¼šæ£€æŸ¥RAGFlowæœåŠ¡æ€§èƒ½æˆ–è°ƒæ•´è¶…æ—¶é…ç½®
- **åˆ†å—å¤±è´¥**ï¼šè°ƒæ•´`chunk_token_count`å‚æ•°æˆ–æ£€æŸ¥chunk_methodè®¾ç½®

## æ–‡æ¡£å¤„ç†åŠŸèƒ½

ç³»ç»Ÿä½¿ç”¨RAGFlowæä¾›å®Œæ•´çš„æ–‡æ¡£å¤„ç†å’Œæ–‡æœ¬åˆ†å—åŠŸèƒ½ï¼š

### æ–‡æ¡£å¤„ç†æµç¨‹
1. **ä¸Šä¼ æ–‡æ¡£**: ä½¿ç”¨ `/upload_documents` ç«¯ç‚¹ä¸Šä¼ æ–‡æ¡£ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒç”¨RAGFlowè¿›è¡Œå¤„ç†
2. **è·å–åˆ†å—**: ä½¿ç”¨ `/analyzing_documents` ç«¯ç‚¹è·å–æ–‡æ¡£åˆ†å—ç»“æœ
3. **ç›´æ¥åˆ†å—**: ä½¿ç”¨ `/chunk_text` ç›´æ¥å¤„ç†æ–‡æœ¬å†…å®¹

### æ”¯æŒçš„æ–‡æ¡£æ ¼å¼
- **PDFæ–‡æ¡£** (.pdf)
- **Wordæ–‡æ¡£** (.docx, .doc)
- **æ–‡æœ¬æ–‡ä»¶** (.txt, .md)
- **PowerPoint** (.pptx)
- **Excel** (.xlsx)

### APIä½¿ç”¨ç¤ºä¾‹

#### 1. æ–‡æ¡£ä¸Šä¼ 
```bash
curl -X POST "http://localhost:5001/upload_documents" \
  -H "Content-Type: application/json" \
  -d '{
    "file_path": "http://example.com/document.pdf"
  }'
```

#### 2. è·å–æ–‡æ¡£åˆ†å—
```bash
curl -X POST "http://localhost:5001/analyzing_documents" \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_id": "dataset_123",
    "document_id": "doc_123456",
    "document_name": "document.pdf",
    "chunk_method": "naive",
    "parser_flag": 1,
    "parser_config": {
      "chunk_token_count": 500
    }
  }'
```

#### 3. ç›´æ¥æ–‡æœ¬åˆ†å—
```bash
curl -X POST "http://localhost:5001/chunk_text" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "è¿™é‡Œæ˜¯é•¿æ–‡æœ¬å†…å®¹...",
    "chunk_method": "naive",
    "parser_flag": 1,
    "parser_config": {
      "chunk_token_count": 400
    }
  }'
```

### å¤„ç†ç»“æœæ ¼å¼
```json
{
  "chunks": [
    {
      "content": "åˆ†å—åçš„æ–‡æœ¬å†…å®¹...",
      "metadata": {
        "chunk_index": 0,
        "token_count": 487,
        "page_number": 1,
        "start_offset": 0,
        "end_offset": 487
      }
    }
  ],
  "document_id": "doc_123456",
  "total_chunks": 5,
  "processing_time": 2.34
}
```

### é…ç½®å‚æ•°è¯´æ˜

#### Parseré…ç½®å‚æ•°
| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `chunk_token_count` | integer | 500 | æ¯ä¸ªåˆ†å—çš„tokenæ•°é‡ |
| `page_size` | integer | 800 | é¡µé¢å¤§å°é™åˆ¶ |

#### é«˜çº§ç”¨æ³•ç¤ºä¾‹
```python
# Pythonè°ƒç”¨æ–‡æ¡£å¤„ç†API
import requests

# ä¸Šä¼ æ–‡æ¡£
files = {'file': open('document.pdf', 'rb')}
data = {'dataset_id': 'my_dataset'}
response = requests.post('http://localhost:5001/upload_document', files=files, data=data)
result = response.json()
document_id = result['document_id']

# å¤„ç†æ–‡æ¡£
process_data = {
    'document_id': document_id,
    'parser_config': {
        'chunk_token_count': 600,
        'page_size': 1000
    }
}
response = requests.post('http://localhost:5001/analyzing_document', json=process_data)
```
